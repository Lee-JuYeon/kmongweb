from openai import OpenAI
from datetime import datetime
from dotenv import load_dotenv
from utils.kmong_checker.db_message import read_all_chatroom_tables, read_all_messages
from collections import defaultdict
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv('openai_api_key')

class GPTManager:
    def __init__(self):
        load_dotenv()  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        openai_api_key = os.getenv('openai_api_key')

        if not openai_api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.client = OpenAI(api_key=openai_api_key)
    
    def fetch_predefined_qna(self, table_id: int):
        """ì´ì „ ëŒ€í™”ë¥¼ í•™ìŠµí•˜ê³ , í˜„ì¬ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ AIê°€ ì¶”ì²œ ë‹µë³€ì„ ìƒì„±"""
        predefined_qna = defaultdict(list)
        chatroom_tables = read_all_chatroom_tables()

        for table_name in chatroom_tables:
            table_id = int(table_name.replace("chatroom_", ""))
            messages = read_all_messages(table_id)
            
            conversation_history = []
            prev_sender = None
            
            for message in messages:
                client_id = message["client_id"]
                sender_id = message["sender_id"]
                text = message["text"]
                
                is_client = client_id == sender_id
                role = "client" if is_client else "me"
                
                if prev_sender == sender_id:
                    conversation_history[-1].append(text)
                else:
                    conversation_history.append([text])
                
                predefined_qna[role].append(text)
                prev_sender = sender_id
        
        # í˜„ì¬ ì±„íŒ…ë°© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        current_messages = read_all_messages(table_id)
        current_conversation = []
        
        for message in current_messages:
            client_id = message["client_id"]
            sender_id = message["sender_id"]
            text = message["text"]
            
            is_client = client_id == sender_id
            current_conversation.append({
                "role": "client" if is_client else "me",  # ê¸°ì¡´ sender -> role ë³€ê²½
                "content": text  # ê¸°ì¡´ text -> content ë³€ê²½
            })
        
        return {
            "training_data": predefined_qna,
            "current_conversation": current_conversation
        }
    
    def get_answer_from_gpt(self, prompt: str) -> str:
        """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
        try:
            completion = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.7,
            )
            return completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error generating response: {e}")
            return "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def format_conversation(self, conversation: list) -> str:
        """ëŒ€í™” ë‚´ìš©ì„ í¬ë§·í•˜ì—¬ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if not conversation:
            return "ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        return "\n".join([f"{msg.get('role', 'unknown')}: {msg.get('content', 'ë‚´ìš© ì—†ìŒ')}" for msg in conversation])
    
    def generate_response(self, conversation: list, response_type: str) -> str:
        """ëŒ€í™” ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±"""
        prompt_templates = {
            "positive_basic": "ê¸°ë³¸ì ì¸ ê¸ì • ë‹µë³€: 'ì˜ˆ, ê°€ëŠ¥í•©ë‹ˆë‹¤.'",
            "positive_detailed": "ìƒì„¸í•œ ê¸ì • ë‹µë³€: 'ì˜ˆ, ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ ì§„í–‰í•˜ë©´ í•´ê²°ë©ë‹ˆë‹¤.'",
            "negative_basic": "ê¸°ë³¸ì ì¸ ê±°ì ˆ ë‹µë³€: 'ì£„ì†¡í•˜ì§€ë§Œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'",
            "negative_with_margin": "ì—¬ì§€ë¥¼ ë‚¨ê¸°ëŠ” ê±°ì ˆ ë‹µë³€: 'í˜„ì¬ ì–´ë µì§€ë§Œ, ì¶”í›„ ê²€í†  ê°€ëŠ¥í•©ë‹ˆë‹¤.'",
            "alternative_solution": "ëŒ€ì²´ ê°€ëŠ¥í•œ ë°©ë²• ì œì‹œ: 'í˜„ì¬ëŠ” ì–´ë µì§€ë§Œ, ì´ëŸ° ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.'"
        }
        
        if response_type not in prompt_templates:
            raise ValueError(f"ì˜ëª»ëœ response_type: {response_type}")

        full_prompt = f"""
        ëŒ€í™” ë‚´ìš©: {self.format_conversation(conversation)}
        ëŒ€ë‹µ ì‹œ ê³ ë ¤í•  ì‚¬í•­:
        {prompt_templates[response_type]}
        """
        return self.get_answer_from_gpt(full_prompt)

    def return_answers(self, message_id: int, conversation: list):
        """ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 5ê°œì˜ ë‹µë³€ì„ ìƒì„±"""
        responses = {
            key: self.generate_response(conversation, key)
            for key in ["positive_basic", "positive_detailed", "negative_basic", "negative_with_margin", "alternative_solution"]
        }
        
        print(f"\nğŸ“© Message ID: {message_id}ì— ëŒ€í•œ AI ë‹µë³€ ë¦¬ìŠ¤íŠ¸ ğŸ“©\n")
        for key, value in responses.items():
            print(f"ğŸ”¹ {key.replace('_', ' ').title()}:\n{value}\n{'-'*50}")
        
        return responses

